{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import akshare as aks\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 92\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Loop through each symbol and calculate the duration\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fe \u001b[38;5;129;01min\u001b[39;00m List:\n\u001b[1;32m---> 92\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mfuture_history_bar\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;66;03m# Calculate the number of days between start_date and end_date for each symbol\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     start_date \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mstrptime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m20141231\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[15], line 10\u001b[0m, in \u001b[0;36mfuture_history_bar\u001b[1;34m(symbol, length, start_date, end_date)\u001b[0m\n\u001b[0;32m      7\u001b[0m end_date \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mstrptime(end_date, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Fetch the futures data\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43maks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures_main_sina\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43msymbol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msymbol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_date\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrftime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_date\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrftime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(data)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Rename the columns for consistency\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\alphaagent\\lib\\site-packages\\akshare\\futures_derivative\\futures_index_sina.py:123\u001b[0m, in \u001b[0;36mfutures_main_sina\u001b[1;34m(symbol, start_date, end_date)\u001b[0m\n\u001b[0;32m    121\u001b[0m data_text \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m    122\u001b[0m data_json \u001b[38;5;241m=\u001b[39m data_text[data_text\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m([\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m: data_text\u001b[38;5;241m.\u001b[39mrfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m])\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 123\u001b[0m temp_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mStringIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_json\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m temp_df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m日期\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m开盘价\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m最高价\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m最低价\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m收盘价\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m成交量\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m持仓量\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m动态结算价\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    125\u001b[0m temp_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m日期\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(temp_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m日期\u001b[39m\u001b[38;5;124m\"\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\alphaagent\\lib\\site-packages\\pandas\\io\\json\\_json.py:815\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 815\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\alphaagent\\lib\\site-packages\\pandas\\io\\json\\_json.py:1025\u001b[0m, in \u001b[0;36mJsonReader.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_object_parser(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_lines(data_lines))\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1025\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_object_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   1027\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mconvert_dtypes(\n\u001b[0;32m   1028\u001b[0m         infer_objects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype_backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype_backend\n\u001b[0;32m   1029\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\alphaagent\\lib\\site-packages\\pandas\\io\\json\\_json.py:1051\u001b[0m, in \u001b[0;36mJsonReader._get_object_parser\u001b[1;34m(self, json)\u001b[0m\n\u001b[0;32m   1049\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1051\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mFrameParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1054\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\alphaagent\\lib\\site-packages\\pandas\\io\\json\\_json.py:1187\u001b[0m, in \u001b[0;36mParser.parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m-> 1187\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1189\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1190\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\.conda\\envs\\alphaagent\\lib\\site-packages\\pandas\\io\\json\\_json.py:1403\u001b[0m, in \u001b[0;36mFrameParser._parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1399\u001b[0m orient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morient\n\u001b[0;32m   1401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1402\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m DataFrame(\n\u001b[1;32m-> 1403\u001b[0m         \u001b[43mujson_loads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1404\u001b[0m     )\n\u001b[0;32m   1405\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1406\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1407\u001b[0m         \u001b[38;5;28mstr\u001b[39m(k): v\n\u001b[0;32m   1408\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m ujson_loads(json, precise_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecise_float)\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1409\u001b[0m     }\n",
      "\u001b[1;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "def future_history_bar(symbol, length=100, start_date=\"20141231\", end_date=\"20250228\"):\n",
    "    # Convert the string dates to datetime objects for future reference\n",
    "    start_date = datetime.strptime(start_date, \"%Y%m%d\")\n",
    "    end_date = datetime.strptime(end_date, \"%Y%m%d\")\n",
    "\n",
    "    # Fetch the futures data\n",
    "    data = aks.futures_main_sina(\n",
    "        symbol=symbol, start_date=start_date.strftime(\"%Y%m%d\"), end_date=end_date.strftime(\"%Y%m%d\")\n",
    "    )\n",
    "    print(data)\n",
    "    # Rename the columns for consistency\n",
    "    data = data.rename(\n",
    "        columns={\n",
    "            \"日期\": \"date\",\n",
    "            \"开盘价\": \"open\",\n",
    "            \"最高价\": \"high\",\n",
    "            \"最低价\": \"low\",\n",
    "            \"收盘价\": \"close\",\n",
    "            \"成交量\": \"volume\",\n",
    "            \"持仓量\": \"open_interest\",\n",
    "            \"动态结算价\": \"settle_price\",\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Convert relevant columns to floats\n",
    "    data[\"open\"] = data[\"open\"].astype(float)\n",
    "    data[\"high\"] = data[\"high\"].astype(float)\n",
    "    data[\"low\"] = data[\"low\"].astype(float)\n",
    "    data[\"close\"] = data[\"close\"].astype(float)\n",
    "    data[\"volume\"] = data[\"volume\"].astype(float)\n",
    "\n",
    "    # Calculate VWAP (Volume Weighted Average Price)\n",
    "    data['vwap'] = data['settle_price'] * data['volume'] / data['volume'].sum()\n",
    "\n",
    "    # Calculate the daily percentage change in close price\n",
    "    data['change'] = data['close'].pct_change()\n",
    "\n",
    "    # Add a formatted date column (YYYYMMDD format)\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    data['date'] = data['date'].dt.strftime('%Y/%m/%d')\n",
    "\n",
    "    # Add stock_code column and convert it to lowercase\n",
    "    # Use the lowercase version of symbol (fe) for 'code' column\n",
    "    data['code'] = [symbol.lower()] * len(data)\n",
    "    # Ensure the date range is continuous from start_date to end_date\n",
    "    all_dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    \n",
    "    # Reindex to ensure every date is covered, filling missing dates\n",
    "    data = data.set_index('date').reindex(all_dates, fill_value=0).reset_index()\n",
    "\n",
    "    # Rename the index column to 'date'\n",
    "    data = data.rename(columns={\"index\": \"date\"})\n",
    "\n",
    "    # Fill missing data: Option 1: Forward fill the missing values, or you can use backward fill or interpolation\n",
    "    # In this case, since we are setting missing values as 0, we don't need further filling\n",
    "    # However, we could also choose to use 'ffill' or 'bfill' if needed for specific columns\n",
    "\n",
    "    # Ensure 'code' column values are all lowercase, just to be safe (though it's already done above)\n",
    "    data['code'] = data['code'].apply(lambda x: symbol.lower())\n",
    "\n",
    "    # Move 'stock_code' to the first column\n",
    "    data.insert(1, 'code', data.pop('code'))\n",
    "    data['factor'] = [1] * len(data)\n",
    "\n",
    "    dir_name = './feature_data'\n",
    "    \n",
    "    # Convert the file name to lowercase\n",
    "    file_name = dir_name + '/' + ''.join(symbol.split('.')).lower() + '.csv'\n",
    "    \n",
    "    # Save the dataframe to a CSV (with lowercase file name)\n",
    "    data.to_csv(file_name, index=False)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# List of symbols\n",
    "List = ['PX0', 'PX2505', 'PX2509', 'PX2506', 'PX2507', 'PX2601', 'PX2504', 'PX2508', 'PX2510', 'PX2511', 'PX2512', 'PX2602', 'PR0', 'PR2505', 'PR2506', 'PR2509', 'PR2504', 'PR2508', 'PR2507', 'PR2601', 'PR2511', 'PR2512', 'SH0', 'SH2505', 'SH2509', 'SH2506', 'SH2507', 'SH2504', 'SH2508', 'SH2601', 'SH2510', 'SH2511', 'SH2512', 'SH2602', 'PK0', 'PK2505', 'PK2510', 'PK2504', 'PK2511', 'PK2601', \n",
    "        'PK2512', 'PF0', 'PF2505', 'PF2506', 'PF2507', 'PF2504', 'PF2509', 'PF2508', 'TA0', 'TA2505', 'TA2509', 'TA2601', 'TA2504', 'TA2506', 'TA2508', 'TA2510', 'TA2511', 'TA2507', 'P0', 'V0', 'P2505', 'P2506', 'P2509', 'P2507', 'B0', 'M0', 'I0', 'JD0', 'L0', 'BB2504', 'Y0', 'C0', 'A0', 'J0', 'JM0', 'CS0', 'EG0', 'RR0', 'LH0', 'LG0', 'EB0', 'RR0', 'IF0', 'TF0', 'T2506', 'IH0', 'IC0', 'TS0', 'IM0',\n",
    "        'SN0', 'NI0', 'SP0', 'NR0', 'SS0', 'BC0', 'AO0', 'BR0', 'EC0']\n",
    "\n",
    "dir_name = './feature_data'\n",
    "\n",
    "# Create a dictionary to hold each symbol and its time span\n",
    "symbol_duration = {}\n",
    "\n",
    "# Loop through each symbol and calculate the duration\n",
    "for fe in List:\n",
    "    data = future_history_bar(symbol=fe)\n",
    "    \n",
    "    # Calculate the number of days between start_date and end_date for each symbol\n",
    "    start_date = datetime.strptime(\"20141231\", \"%Y%m%d\")\n",
    "    end_date = datetime.strptime(\"20250228\", \"%Y%m%d\")\n",
    "    duration = (end_date - start_date).days\n",
    "    \n",
    "    # Store the symbol and its duration\n",
    "    symbol_duration[fe] = duration\n",
    "\n",
    "# Sort symbols based on duration (longest duration first)\n",
    "sorted_symbols = sorted(symbol_duration, key=symbol_duration.get, reverse=True)\n",
    "\n",
    "# Now process the symbols in the order of longest duration first\n",
    "for fe in sorted_symbols:\n",
    "    data = future_history_bar(symbol=fe)\n",
    "    data.to_csv(dir_name + '/' + fe.lower() + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [date, code, open, high, low, close, volume, open_interest, settle_price, vwap, change]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 假设您的 .bin 文件存储在当前目录下，文件名为 'data.bin'\n",
    "data = np.fromfile('high.day.bin', dtype=np.float32)  # 根据实际数据类型修改 dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2469,)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alphaagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
