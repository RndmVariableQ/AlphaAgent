potential_direction_transformation: |-
  It's the first round, the user provided a potential direction: "{{ potential_direction }}". Referring to it, you need to transform it into a hypothesis in formal language that is clear and actionable for factor generation. Consider the following aspects while formulating the hypothesis:
  1. **Clarity**: Ensure the hypothesis is specific and unambiguous.
  2. **Actionability**: The hypothesis should suggest a clear path for experimentation or investigation.
  3. **Relevance**: Ensure the hypothesis is directly related to the potential direction provided by the user.


hypothesis_and_feedback: |-
  {% for hypothesis, experiment, feedback in trace.hist[-10:] %}
  Hypothesis {{ loop.index }}: {{ hypothesis }}
  Corresponding Code (that leads to the difference in performance): {{experiment.sub_workspace_list[0].code_dict.get("model.py")}}
  Observation on the result with the hypothesis: {{ feedback.observations }}
  Feedback on the original hypothesis:  {{ feedback.hypothesis_evaluation }}
  New Feedback for Context (For you to agree or improve upon):  {{ feedback.new_hypothesis }}
  Reasoning for new hypothesis:  {{ feedback.reason }}
  Did changing to this hypothesis work? (focus on the change):  {{ feedback.decision }}
  {% endfor %}

hypothesis_output_format: |-
  The output should follow JSON format. Do not add any other text in your response. The schema is as follows:
  {
  "hypothesis": "TEXT ONLY. The new hypothesis generated based on the information provided.",
  "concise_knowledge": "TEXT ONLY. Transferable knowledge based on theoretical principles. Use conditional grammar. eg. 'If...., ..; When..., .; and etc' Make sure that you state things clearly without ambiguity. Eg. avoid saying 'previous hypothesis', because one wouldn't know what that is.",
  "concise_observation": "TEXT ONLY. It focuses on the observation of the given scenario, data characteristics, or previous experiences (failures & succeses).",
  "concise_justification": "TEXT ONLY. Justify the hypothesis based on theoretical principles or initial assumptions.",
  "concise_specification": "TEXT ONLY. Define the scope, conditions, constraints of the hypothesis. Specify the expected relationships, variables, and thresholds, ensuring testability and relevance to the observed data."
    }



model_hypothesis_specification: |-
  Additional Specifications:
    
    Hypotheses should grow and evolve based on the previous hypothesis. If there is no previous hypothesis, start with something simple. Gradually Build Up Upon previous hypothesis & feedbacks. In each round, hypothesis is different. Pay attention to your previous hypothesis.

    Ensure that the hypothesis focuses on the architecture of a PyTorch model. Each hypothesis should address specific architectural choices such as the type of layers, activation functions, regularization techniques, and the overall structure of the model. Avoid hypotheses related to input features or optimization processes.

  Remember: if there is no hypothesis, start with something simple like MLP.

  Usually, a larger model works better than a smaller one. 

  Logic for generating a new hypothesis: If the previous hypothesis works, try to inherit from it and grow deeper. If the previous hypotheis doesn't work, try to make changes in the current level.

  Sample hypothesis evolution loop: (This is the entire loop, see what stage you are at. We want hypothesis to continue growing.) Levels include **Model Type**, **Layer Configuration**, **Activation Functions**, **Regularization Techniques**

    1st Round Hypothesis: The model should be a CNN. 

    2nd Round Hypothesis (If first round worked: CNN is the model type level, which means that we should extend to the next level, like layer configuration): The model should be a CNN. The CNN should have 5 convolutional layers. (Reasoning: As CNN worked, we now specify the layers specification to grow the hypothesis deeper.)

    3rd Round Hypothesis (If second round didn't work): The model should be a CNN. The CNN should have 3 convolutional layers. (Reasoning: As 5-layer structure didn't work in the 2nd round hypothesis, try something else within the layer configuration level.)

    4th Round Hypothesis (If third round worked): The model should be a CNN. The CNN should have 3 convolutional layers. Use Leaky ReLU activation for all layers. (As last round worked, now proceed to the next level: activation functions)
    
    5th Round Hypothesis (If fourth round worked): The model should be a CNN. The CNN should have 3 convolutional layers. Use Leaky ReLU activation for all layers. Use dropout regularization with a rate of 0.5. (Similar Reasoning & Continuing to Grow to the dropout setup)

    6th Round Hypothesis (If fourth round didn't work):  The model should be a CNN. The CNN should have 5 convolutional layers. Use Leaky ReLU activation for all layers. Use dropout regularization with a rate of 0.3. (Reasoning: As regularisation rate of 0.5 didn't work, we only change a new regularisation and keep the other elements that worked. This means making changes in the current level.)    

factor_hypothesis_specification: |-
  1. **Data-Driven Hypothesis Formation:**  
    - Ground hypotheses within the scope of available data for seamless testing.
    - Align hypotheses with the temporal, cross-sectional, and distributional properties of the data.
    - Avoid overfitting by focusing on robust, economically intuitive, and innovative relationships. 

  2. **Justification of the Hypothesis:**  
    - Use observed market patterns to creatively infer underlying economic or behavioral drivers.
    - Build on empirical evidence while exploring innovative connections or untested relationships.
    - Propose actionable insights that challenge conventional assumptions, yet remain testable.
    - Emphasize the factor's potential to uncover unique, predictive market behaviors.

  3. **Continuous Optimization and Exploration:**  
      - Refine the first hypothesis iteratively by testing across different variants. 
      - Incorporate feedback from empirical results to enhance the factor's predictive power.


function_lib_description: |-
  Only the following operations are allowed in expression: 
  ### **Cross-sectional Functions**
  - **RANK(A)**: Ranking of each element in the cross-sectional dimension of A.
  - **ZSCORE(A)**: Z-score of each element in the cross-sectional dimension of A.
  - **MEAN(A)**: Mean value of each element in the cross-sectional dimension of A.
  - **STD(A)**: Standard deviation in the cross-sectional dimension of A.
  - **SKEW(A)**: Skewness in the cross-sectional dimension of A.
  - **KURT(A)**: Kurtosis in the cross-sectional dimension of A.
  - **MAX(A)**: Maximum value in the cross-sectional dimension of A.
  - **MIN(A)**: Minimum value in the cross-sectional dimension of A.
  - **MEDIAN(A)**: Median value in the cross-sectional dimension of A

  ### **Time-Series Functions**
  - **DELTA(A, n)**: Change in value of A over n periods.
  - **DELAY(A, n)**: Value of A delayed by n periods.
  - **TS_MEAN(A, n)**: Mean value of sequence A over the past n days.
  - **TS_SUM(A, n)**: Sum of sequence A over the past n days.
  - **TS_RANK(A, n)**: Time-series rank of the last value of A in the past n days.
  - **TS_ZSCORE(A, n)**: Z-score for each sequence in A over the past n days.
  - **TS_MEDIAN(A, n)**: Median value of sequence A over the past n days.
  - **TS_PCTCHANGE(A, p)**: Percentage change in the value of sequence A over p periods.
  - **TS_MIN(A, n)**: Minimum value of A in the past n days.
  - **TS_MAX(A, n)**: Maximum value of A in the past n days.
  - **TS_ARGMAX(A, n)**: The index (relative to the current time) of the maximum value of A over the past n days.
  - **TS_ARGMIN(A, n)**: The index (relative to the current time) of the minimum value of A over the past n days.
  - **TS_QUANTILE(A, p, q)**: Rolling quantile of sequence A over the past p periods, where q is the quantile value between 0 and 1.
  - **TS_STD(A, n)**: Standard deviation of sequence A over the past n days.
  - **TS_VAR(A, p)**: Rolling variance of sequence A over the past p periods.
  - **TS_CORR(A, B, n)**: Correlation coefficient between sequences A and B over the past n days.
  - **TS_COVARIANCE(A, B, n)**: Covariance between sequences A and B over the past n days.
  - **TS_MAD(A, n)**: Rolling Median Absolute Deviation of sequence A over the past n days.
  - **PERCENTILE(A, q, p)**: Quantile of sequence A, where q is the quantile value between 0 and 1. If p is provided, it calculates the rolling quantile over the past p periods.
  - **HIGHDAY(A, n)**: Number of days since the highest value of A in the past n days.
  - **LOWDAY(A, n)**: Number of days since the lowest value of A in the past n days.
  - **SUMAC(A, n)**: Cumulative sum of A over the past n days.

  ### **Moving Averages and Smoothing Functions**
  - **SMA(A, n, m)**: Simple moving average of A over n periods with modifier m.
  - **WMA(A, n)**: Weighted moving average of A over n periods, with weights decreasing from 0.9 to 0.9^(n).
  - **EMA(A, n)**: Exponential moving average of A over n periods, where the decay factor is 2/(n+1).
  - **DECAYLINEAR(A, d)**: Linearly weighted moving average of A over d periods, with weights increasing from 1 to d.

  ### **Mathematical Operations**
  - **PROD(A, n)**: Product of values in A over the past n days. Use `*` for general multiplication.
  - **LOG(A)**: Natural logarithm of each element in A.
  - **SQRT(A)**: Square root of each element in A.
  - **POW(A, n)**: Raise each element in A to the power of n.
  - **SIGN(A)**: Sign of each element in A, one of 1, 0, or -1.
  - **EXP(A)**: Exponential of each element in A.
  - **ABS(A)**: Absolute value of A.
  - **MAX(A, B)**: Maximum value between A and B.
  - **MIN(A, B)**: Minimum value between A and B.
  - **INV(A)**: Reciprocal (1/x) of each element in sequence A.
  - **FLOOR(A)**: Floor of each element in sequence A.
  
  ### **Conditional and Logical Functions**
  - **COUNT(C, n)**: Count of samples satisfying condition C in the past n periods. Here, C is a logical expression, e.g., `$close > $open`.
  - **SUMIF(A, n, C)**: Sum of A over the past n periods if condition C is met. Here, C is a logical expression.
  - **FILTER(A, C)**: Filtering multi-column sequence A based on condition C. Here, C is presented in a logical expression form, with the same size as A.
  - **(C1)&&(C2)**: Logical operation "and". Both C1 and C2 are logical expressions, such as A > B.
  - **(C1)||(C2)**: Logical operation "or". Both C1 and C2 are logical expressions, such as A > B.
  - **(C1)?(A):(B)**: Logical operation "If condition C1 holds, then A, otherwise B". C1 is a logical expression, such as A > B.

  ### **Regression and Residual Functions**
  - **SEQUENCE(n)**: A single-column sequence of length n, ranging from 1 to integer n. `SEQUENCE()` should always be nested in `REGBETA()` or `REGRESI()` as argument B.
  - **REGBETA(A, B, n)**: Regression coefficient of A on B using the past n samples, where A MUST be a multi-column sequence and B a single-column or multi-column sequence.
  - **REGRESI(A, B, n)**: Residual of regression of A on B using the past n samples, where A MUST be a multi-column sequence and B a single-column or multi-column sequence.

  ### **Technical Indicators**
  - **RSI(A, n)**: Relative Strength Index of sequence A over n periods. Measures momentum by comparing the magnitude of recent gains to recent losses.
  - **MACD(A, short_window, long_window)**: Moving Average Convergence Divergence (MACD) of sequence A, calculated as the difference between the short-term (short_window) and long-term (long_window) exponential moving averages.
  - **BB_MIDDLE(A, n)**: Middle Bollinger Band, calculated as the n-period simple moving average of sequence A.
  - **BB_UPPER(A, n)**: Upper Bollinger Band, calculated as middle band plus two standard deviations of sequence A over n periods.
  - **BB_LOWER(A, n)**: Lower Bollinger Band, calculated as middle band minus two standard deviations of sequence A over n periods.


  Note that:
  - Only the variables provided in data (e.g., '$open'), arithmetic operators ('+', '-', '*', '/'), logical operators ('&&', '||'), and the operations above are allowed in the factor expression. 
  - Make sure your factor expression contain at least one variables within the dataframe columns (e.g. $open), combined with registered operations above. Do NOT use any undeclared variable (e.g. 'n', 'w_1') and undefined symbols (e.g., '=') in the expression. 


factor_experiment_output_format: |-
  Do NOT use any undeclared variables. The factor expression should be strictly based on the function library (e.g. RANK(.)) and the variables provided in data (e.g., $open). 
  The output should follow JSON format without other content. The schema is as follows:
  {
      "factor name 1": {
          "description": "description of factor 1",
          "variables": {
              "variable or function name 1": "description of variable or function 1",
              "variable or function name 2": "description of variable or function 2"
          }
          "formulation": "A LaTeX formula of factor 1",
          "expression": "An expression of factor 1, based on functions and variable mentioned",
      },
      "factor name 2": {
          "description": "description of factor 2",
          "variables": {
              "variable or function name 1": "description of variable or function 1",
              "variable or function name 2": "description of variable or function 2"
          }
          "formulation": "A LaTeX formula of factor 2",
          "expression": "An expression of factor 2, based on functions and variable mentioned",
      }
      # Don't add ellipsis (...) or any filler text that might cause JSON parsing errors here!
  }

  Here is an example:
  {
      "Normalized_Intraday_Range_Factor_10D": {
          "description": "This factor integrates candlestick movement patterns with market volatility to enhance predictive accuracy for short-term price movements. The factor computes the normalized difference between the candlestick body size and the standard deviation of closing prices over a 10-day period.",
          "variables": {
              "$close": "Close price of the stock on that day.",
              "$open": "Open price of the stock on that day.",
              "ABS(A)": "Absolute value of A.",
              "STD(A, n)": "Standard deviation of sequence A over the past n days."
          }
          "formulation": "NIR_\\text{10D} = \\frac{\\text{ABS}(\\text{close} - \\text{open})}{\\text{STD}(\\text{close}, 10)}",
          "expression": "ABS($close - $open) / (STD($close, 10) + 1e-8)",
      },
      "Volume_Range_Correlation_Factor_20D": {
          "description": "This factor measures the correlation between the candlestick range (high - low) and the trading volume over a 20-day period, aiming to capture the relationship between price range and market participation.",
          "variables": {
              "$high": "High price of the stock on that day.",
              "$low": "Low price of the stock on that day.",
              "$volume": "Volume of the stock on that day.",
              "CORR(A, B, n)": "Correlation coefficient between sequences A and B over the past n days."
          }
          "formulation": "VRC_\\text{20D} = \\text{CORR}(\\text{high} - \\text{low}, \\text{volume}, 20)",
          "expression": "CORR($high - $low, $volume, 20)",
      }
  }

model_experiment_output_format: |-
  So far please only design one model to test the hypothesis! 
  The output should follow JSON format. The schema is as follows: 
  {
    "model_name 1 (The name of the model)": {
        "description": "A detailed description of the model",
        "formulation": "A LaTeX formula representing the model's formulation",
        "architecture": "A detailed description of the model's architecture, e.g., neural network layers or tree structures",
        "variables": {
            "\\hat{y}_u": "The predicted output for node u",
            "variable_name_2": "Description of variable 2",
            "variable_name_3": "Description of variable 3"
        },
        "hyperparameters": {
            "hyperparameter_name_1": "value of hyperparameter 1",
            "hyperparameter_name_2": "value of hyperparameter 2",
            "hyperparameter_name_3": "value of hyperparameter 3"
        },
        "model_type": "Tabular or TimeSeries"  # Should be one of "Tabular" or "TimeSeries"
    },
    "model_name 2 (The name of the model)": {
        ...
    }
  }
  Usually a larger model works better than a smaller one. Hence, the parameters should be larger.

factor_feedback_generation:
  system: |-
    Please understand the following operation logic and then make your feedback that is suitable for the scenario:

    {{ scenario }}

    You will receive a hypothesis, multiple tasks with their factors, their results, and the SOTA result. 
    Your feedback should specify whether the current result supports or refutes the hypothesis, compare it with previous SOTA (State of the Art) results, and suggest improvements or new directions.
    Please understand the following operation logic and then make your feedback that is suitable for the scenario:
      1. Logic Explanation:
          - Each hypothesis represents a theoretical framework that can be refined through multiple iterations
          - Focus on exploring various implementations within the same theoretical framework
          - Continuously optimize factor construction methods before considering direction changes
      
      2. Development Directions:
          - Hypothesis Refinement:
              - Suggest specific improvements in factor construction methodology
              - Propose alternative mathematical representations of the same theoretical concept
              - Identify potential variations in parameter selection and combination methods
          
          - Factor Enhancement:
              - Fine-tune existing factors through parameter or structure optimization
              - Explore different normalization and standardization approaches
              - Consider alternative window sizes and weighting schemes
          
          - Methodological Iteration:
              - Refine the mathematical expression while maintaining the core concept
              - Suggest complementary signals within the same theoretical framework
              - Propose robust variations of the current methodology
      
      3. Final Goal:
          - The ultimate goal is to continuously mine factors that surpass each iteration to maintain the best SOTA.
    
      When analyzing results:
      1. **Factor Construction Analysis:**
          - Evaluate how different construction methods affect factor performance
          - Identify which aspects of the construction process contribute most to performance
          - Suggest specific modifications to improve factor robustness
      
      2. **Parameter Sensitivity:**
          - Analyze the impact of different parameter choices
          - Recommend parameter ranges for further exploration
          - Identify critical components in the factor construction process

    Focus on Continuous Refinement:
      - Exhaust all possible variations within the current theoretical framework
      - Document the effectiveness of different implementation approaches
      
    Please provide detailed and constructive feedback for future exploration.
    Respond in JSON format. Example JSON structure for Result Analysis:
    {
      "Observations": "Your overall observations here",
      "Feedback for Hypothesis": "Observations related to the hypothesis",
      "New Hypothesis": "Your new hypothesis here",
      "Reasoning": "Reasoning for the new hypothesis",
      "Replace Best Result": "yes or no"
    }
  user: |-
    Target hypothesis: 
    {{ hypothesis_text }}
    Tasks and Factors:
    {% for task in task_details %}
      - {{ task.factor_name }}: {{ task.factor_description }}
        - Factor Formulation: {{ task.factor_formulation }}
        - Variables: {{ task.variables }}
        - Factor Implementation: {{ task.factor_implementation }}
        {% if task.factor_implementation == "False" %}
        **Note: This factor was not implemented in the current experiment. Only the hypothesis for implemented factors can be verified.**
        {% endif %}
    {% endfor %}
    Combined Results: 
    {{ combined_result }}
    
    Analyze the combined result in the context of its ability to:
    1. Support or refute the hypothesis.
    2. Show improvement or deterioration compared to the SOTA experiment.

    Evaluation Metrics Explanations:
    Below are the financial meanings of each metric, which should be used to judge the results:

    - 1day.excess_return_without_cost.max_drawdown: Measures the maximum loss from a peak to a trough without considering transaction costs. (the smaller the better)
    - 1day.excess_return_without_cost.information_ratio: Evaluates the excess return per unit of risk without considering transaction costs. (the bigger the better)
    - 1day.excess_return_without_cost.annualized_return: Annualized return without considering transaction costs. (the bigger the better)
    - IC: Measures the correlation between predicted returns (\hat{y}) and actual returns (y), using Pearson correlation. (the bigger the better)

    When judging the results:
      1. **Recommendation for Replacement:**
        - If the new factor shows a significant improvement in the annualized return without transaction costs, recommend it to replace the current best result.
        - If the annualized return and any other single metric are better than SOTA, recommend the replacement.
        - Minor variations in other metrics are acceptable as long as the annualized return improves.

    Note: Only factors with 'Factor Implementation' as True are implemented and tested in this experiment. If 'Factor Implementation' is False, the hypothesis for that factor cannot be verified in this run.

model_feedback_generation:
  system: |-
    You are a professional result analysis assistant. You will receive a result and a hypothesis.
    Your task is to provide feedback on how well the result supports or refutes the hypothesis by judging from the observation of performance increase or decrease.
    Please provide detailed and constructive feedback. Note that as hypothesis evolve, a general trend should be that the model grows larger. 
    Example JSON Structure for Result Analysis:
    {
      "Observations": "Your overall observations here",
      "Feedback for Hypothesis": "Observations related to the hypothesis",
      "New Hypothesis": "Put your new hypothesis here.",
      "Reasoning": "Provide reasoning for the hypothesis here.",
      "Decision": <true or false>,
    }

    Focus on the changes in hypothesis and justify why do hypothesis evolve like this. Also, increase complexity as the hypothesis evolves  (give more layers, more neurons, and etc)
    
    Logic for generating a new hypothesis: If the previous hypothesis works, try to inherit from it and grow deeper. If the previous hypotheis doesn't work, try to make changes in the current level.

    Sample hypothesis evolution loop: (This is the entire loop, see what stage you are at. We want hypothesis to continue growing.) Levels include **Model Type**, **Layer Configuration**, **Activation Functions**, **Regularization Techniques**

      1st Round Hypothesis: The model should be a CNN. 

      2nd Round Hypothesis (If first round worked: CNN is the model type level, which means that we should extend to the next level, like layer configuration): The model should be a CNN. The CNN should have 5 convolutional layers. (Reasoning: As CNN worked, we now specify the layers specification to grow the hypothesis deeper.)

      3rd Round Hypothesis (If second round didn't work): The model should be a CNN. The CNN should have 3 convolutional layers. (Reasoning: As 5-layer structure didn't work in the 2nd round hypothesis, try something else within the layer configuration level.)

      4th Round Hypothesis (If third round worked): The model should be a CNN. The CNN should have 3 convolutional layers. Use Leaky ReLU activation for all layers. (As last round worked, now proceed to the next level: activation functions)
      
      5th Round Hypothesis (If fourth round worked): The model should be a CNN. The CNN should have 3 convolutional layers. Use Leaky ReLU activation for all layers. Use dropout regularization with a rate of 0.5. (Similar Reasoning & Continuing to Grow to the dropout setup)

      6th Round Hypothesis (If fourth round didn't work):  The model should be a CNN. The CNN should have 5 convolutional layers. Use Leaky ReLU activation for all layers. Use dropout regularization with a rate of 0.3. (Reasoning: As regularisation rate of 0.5 didn't work, we only change a new regularisation and keep the other elements that worked. This means making changes in the current level.)    

    
  user: |-
    We are in an experiment of finding hypothesis and validating or rejecting them so that in the end we have a powerful model generated.
    Here are the context: {{context}}. 

    {% if last_hypothesis %} 
    Last Round Information:
    Hypothesis: {{last_hypothesis.hypothesis}}
    Task: {{last_task}}
    Code Implemented: {{last_code}}
    Result: {{last_result}}
    {% else %}
    This is the first round. No previous information available. As long as the performance is not too negative (eg.ICIR is greater than 0), treat it as successful. Do not set the threshold too high.
    {% endif %} 
    
    Now let's come to this round. You will receive the result and you will evaluate if the performance increases or decreases. 
    Hypothesis: {{hypothesis.hypothesis}}
    Experiment Setup: {{exp.sub_tasks[0]}}
    Code Implemented: {{exp.sub_workspace_list[0].code_dict.get("model.py")}}
    Relevant Reasoning: {{hypothesis.reason}}
    Result: {{exp.result}}

    Compare and observe. Which result has a better return and lower risk? If the performance increases, the hypothesis should be considered positive (working). 
    Hence, with the hypotheses, relevant reasoning, and results in mind (comparison), provide detailed and constructive feedback and suggest a new hypothesis. 


hypothesis_gen:
  system_prompt: |-
    The user is working on generating new hypotheses for the {{targets}} in a data-driven research and development process. 
    The {{targets}} are used in the following scenario:
    {{scenario}}
    The user has already proposed several hypotheses and conducted evaluations on them. This information will be provided to you. 
    Your task is to check whether a hypothesis has already been generated. If one exists, follow it or generate an improved version.
    {% if hypothesis_specification %}
    To assist you in formulating new hypotheses, the user has provided some additional information:
    {{hypothesis_specification}}.
    **Important:** If the hypothesis_specification outlines the next steps you need to follow, ensure you adhere to those instructions.
    {% endif %}
    Please generate the output using the following format and specifications. Avoid making assumptions that depend on data outside the supported data range.
    {{ hypothesis_output_format }}

  user_prompt: |-
    {% if hypothesis_and_feedback|length == 0 %}It is the first round of hypothesis generation. The user has no hypothesis on this scenario yet. You are encouraged to propose an innovative hypothesis that diverges significantly from existing perspectives.
    {% elif hypothesis_and_feedback|length > 0 and round == 0 %}{{ hypothesis_and_feedback }}
    {% else %}It is not the first round, the user has made several hypothesis on this scenario and did several evaluation on them.
    The former hypothesis and the corresponding feedbacks are as follows (focus on the last one & the new hypothesis that it provides and reasoning to see if you agree):
    {{ hypothesis_and_feedback }}
    {% endif %}
    {% if RAG %}
    To assist you in generating new {{targets}}, we have provided the following information: {{RAG}}.
    **Note:** The provided RAG is for reference only. 
    You must carefully assess whether the RAG aligns with the {{targets}}. 
    If it does not, it should not be used. Exercise caution and make your own judgment.
    {% endif %}
    Also generate the relevant keys for the reasoning and the distilled knowledge that follows. For those keys, in particular for knowledge, explain in the context of the specific scenario to build up domain knowledge in the specific field rather than general knowledge.

hypothesis2experiment:
  system_prompt: |-
    The user is trying to generate new {{targets}} based on the hypothesis generated in the previous step. 
    The {{targets}} are used in certain scenario, the scenario is as follows:
    {{ scenario }}

    The user will use the {{targets}} generated to do some experiments. The user will provide this information to you:
    1. The target hypothesis you are targeting to generate {{targets}} for.
    2. The hypothesis generated in the previous steps and their corresponding feedbacks.
    3. Former proposed {{targets}} on similar hypothesis.
    4. Duplicated sub-expressions that you have to evade for better factor originality and novelty. 
    5. Some additional information to help you generate new {{targets}}.


    1. **2-3 Factors per Generation:**
      - Ensure each generation produces 2-3 factors.
      - Balance simplicity and innovation to build a robust factor library.
      - Note that each factor is independent. Please do NOT reference other factors within the factor expression.


    2.**Key Considerations in Factor Construction:**
      - **Data Preprocessing and Standardization:**
          - Avoid using raw prices and volumes directly due to scale differences
          - Use relative changes or standardized data (e.g., RANK(), ZSCORE())
          - Convert prices to returns, e.g. `(DELTA($close, 1)/$close)` instead of price levels
          - Transform volume into relative changes, e.g. `(DELTA($volume, 1)/$volume)`

      - **Time Series Processing:**
          - Consider appropriate sample periods for indicators requiring historical data
          - Choose suitable window sizes for moving averages SMA(), EMA(), WMA()

      - **Normalization and Stability:**
          - Add small constants (e.g., 1e-8) to denominators to prevent division by zero
          - Use TS_ZSCORE() for factor value standardization
          - Consider SIGN() to reduce impact of extreme values
          - Apply MAX(MIN(x, upper), lower) for value truncation

      - **Cross-sectional Treatment:**
          - Apply RANK() or ZSCORE() for cross-sectional comparability
          - Use FILTER() for outlier handling
          - Ensure sufficient window length for correlation calculations

      - **Robustness Considerations:**
          - Validate factor stability across multiple time windows
          - Consider MEDIAN() over MEAN() to reduce outlier impact
          - Apply moving averages to smooth high-frequency variations
  
      - **Flexibility Considerations:**  
          - Allow for a range of values or flexibility when defining factors, rather than imposing strict equality constraints.
          - For example, in expression `(TS_MIN($low, 10) == DELAY(TS_MIN($low, 10), 1))`, `==` is too restrictive. 
          - Instead, use a range-based approach like: `(TS_MIN($low, 10) < DELAY(TS_MIN($low, 10), 1) + 1/10 * STD($low, 20)) && (TS_MIN($low, 10) > DELAY(TS_MIN($low, 10), 1) - 1/10 * STD($low, 20))`.

      - **Handling Duplicated Sub-expressions:**
            - When given specific duplicated sub-expressions to avoid, ensure new factor expressions use alternative calculations
            - Replace duplicated patterns with semantically similar but structurally different expressions
            - For example, if `ABS($close - $open)` is flagged as duplicated:
                - Consider using `($high - $low)` for price range
                - Use `SIGN($close - $open) * ($close - $open)` for directional magnitude
                - Explore other price difference combinations like `($high - $low) / ($open + $close)`
            - Maintain factor interpretability while avoiding structural repetition
            - Focus on unique combinations of operators and variables to ensure originality

    Please generate the output following the format below:
    {{ experiment_output_format }}

    Strictly adhere to the syntax requirements of factor expressions; do not use undeclared variables (e.g., n) or functions.
    
  user_prompt: |-
    The user has made several hypothesis on this scenario and did several evaluation on them.
    The target hypothesis you are targeting to generate {{targets}} for is as follows:
    {{ target_hypothesis }}
    
    The former hypothesis and the corresponding feedbacks are as follows:
    {{ hypothesis_and_feedback }}

    When constructing factor expressions, you are restricted to utilizing only the following daily-level variable:
    - $open: open price of the stock on that day.
    - $close: close price of the stock on that day.
    - $high: high price of the stock on that day.
    - $low: low price of the stock on that day.
    - $volume: volume of the stock on that day.
    - $return: daily return of the stock on that day.

    Allowed operators and functions in factor expressions are: 
    {{function_lib_description}}


    {% if expression_duplication %}
    **Alert: Duplication Detected in Previous Factor Expressions**
    {{ expression_duplication }}

    Recommendations:
    - Avoid the duplicated sub-expressions above
    - Generate novel factor by uniquely combining data variables and operations
    - Experiment with a mix of mathematical operations (e.g., exponentiation, logarithmic transformations) to construct expressions that reveal different relationships and interactions among variables.
    - Replace raw variables with transformed variants to enhance expressiveness, such as using `$open`, `$close/TS_MEAN($close, 10)`, or `($open + $close) / 2` instead of `$close` to normalize or adjust for trends.
    {% endif %}

    Please generate the new {{targets}} in JSON format based on the information above.



expression_duplication: |-
  - Proposed Expression: {{ prev_expression }}
  - Duplicated Sub-expression Size: {{ duplicated_subtree_size }}
  - Duplicated Sub-expression: {{ duplicated_subtree }}

